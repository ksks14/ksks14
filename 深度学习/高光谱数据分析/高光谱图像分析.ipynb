{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 高光谱图像处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  分割数据，存入文件，构建数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**同时遍历总矩阵以及标签矩阵，两个矩阵二维平面对应，通过label矩阵判断，如果为0就略掉，说明是黑点，如果不是零，就取一部分，构建一个新的.mat文件，将这些文件填入到一个总的文件夹中，作为总的数据集。**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting completed!\n",
      "Deleting completed!\n",
      "Deleting completed!\n",
      "Deleting completed!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "导入os库删除path目录下的所有文件，用于清除文件夹。这里用于清除先前存储的.mat文件，重构数据集。\n",
    "'''\n",
    "import os\n",
    "def del_files(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            os.remove(os.path.join(root, name))\n",
    "    print('Deleting completed!')\n",
    "# test\n",
    "if __name__ == \"__main__\":\n",
    "    path_1='all_data\\\\'\n",
    "    path_2='all_test_data\\\\'\n",
    "    path_3='all_train_data\\\\'\n",
    "    path_4='all_test_new_data//'\n",
    "    del_files(path_1)\n",
    "    del_files(path_2)\n",
    "    del_files(path_3)\n",
    "    del_files(path_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件路径等信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "data_total_path=\"all_data//\"\n",
    "data_train_path=\"all_train_data//\"\n",
    "data_test_path=\"all_test_data//\"\n",
    "data_test_new_path=\"all_test_new_data//\"\n",
    "cluster_message_path=\"cluster//\"\n",
    "\n",
    "\n",
    "each_other_dist_file=\"each_other_dist.csv\"\n",
    "\n",
    "label_file_name=\"Indian_pines_gt.mat\"\n",
    "data_file_name=\"Indian_pines.mat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完成数据集的构建\n",
    "\n",
    "* 求得总数据集\n",
    "* 更新三个空文件夹\n",
    "* 以某种算法分配测试集和训练集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_file=scio.loadmat(label_file_name)\n",
    "data_file=scio.loadmat(data_file_name)\n",
    "\n",
    "\n",
    "label_array=label_file['indian_pines_gt']\n",
    "data_array=data_file['indian_pines']\n",
    "\n",
    "\n",
    "#矩阵类型为numpy.array，shape为145*145*220。\n",
    "#处理矩阵外围数据\n",
    "\n",
    "data_fin_array=np.zeros([151,151,220],np.uint8)\n",
    "data_fin_array[3:148,3:148,:]=data_array\n",
    "\n",
    "index=0\n",
    "\n",
    "#构建总数据集\n",
    "#构建训练集\n",
    "#构建测试集\n",
    "for i in range(3,148):\n",
    "    for j in range(3,148):\n",
    "        index+=1\n",
    "        #不为0符合添加条件\n",
    "        if label_array[i-3][j-3]!=0 :\n",
    "            data_now=data_fin_array[i-3:i+4,j-3:j+4,:]\n",
    "            scio.savemat(data_total_path+str(i)+str(j)+\".mat\",{\"label\":label_array[i-3][j-3],\"data\":data_now})\n",
    "            if index%30==0:\n",
    "                scio.savemat(data_test_path+str(i)+str(j)+\".mat\",{\"label\":label_array[i-3][j-3],\"data\":data_now})\n",
    "            if i==3 or j==3 or i==147 or j==147 :\n",
    "                scio.savemat(data_train_path+str(i)+str(j)+\".mat\",{\"label\":label_array[i-3][j-3],\"data\":data_now})\n",
    "                continue\n",
    "            if index%10==0 :\n",
    "                scio.savemat(data_train_path+str(i)+str(j)+\".mat\",{\"label\":label_array[i-3][j-3],\"data\":data_now})\n",
    "        else:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于快速搜索和局部密度峰值的聚类\n",
    "\n",
    "## 目标：用所有数据点做聚类\n",
    "\n",
    "\n",
    "* 处理数据\n",
    "* 为数据打点\n",
    "* 计算欧氏距离\n",
    "* 将数据写入csv文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "dist:calculate the Euclidean distance between vectors\n",
    "dist函数：计算向量间的欧氏距离\n",
    "'''\n",
    "def dist(vec_a,vec_b):\n",
    "    return np.sqrt(np.sum(np.square(vec_a-vec_b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10044\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "这里写入csv文件，由于文件数量过大，以及欧氏距离的复杂计算，本设备不支持计算过大的数据，选取其中一部分数据进行测试。\n",
    "'''\n",
    "for root, dirs, files in os.walk(data_total_path):\n",
    "    file_len=len(files)\n",
    "    print(file_len)\n",
    "    with open(each_other_dist_file,\"w\",newline=\"\") as file_write:\n",
    "        #创建写入对象\n",
    "        file_writer=csv.writer(file_write)\n",
    "        for i in range(int(file_len*0.05)-1):\n",
    "            for j in range(i+1,int(file_len*0.05)):\n",
    "                #这里注意更新列表，否则每一次添加列表会导致文件巨大。。。。\n",
    "                write_to_list=[]\n",
    "                vec_a=scio.loadmat(root+files[i])[\"data\"]\n",
    "                vec_b=scio.loadmat(root+files[j])[\"data\"]\n",
    "                dist_now=dist(vec_a,vec_b)\n",
    "                write_to_list.append(i)\n",
    "                write_to_list.append(j)\n",
    "                write_to_list.append(dist_now)\n",
    "                file_writer.writerow(write_to_list)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对部分数据，做聚类任务，基于快速搜索和局部密度峰值的聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载文件\n",
      "198\n",
      "199\n",
      "199\n",
      "average percentage of neighbours: 2.0\n",
      "截断距离是: 685.7317259686911\n",
      "767.6405408783462\n",
      "Generated file:DECISION GRAPH\n",
      "column 1:Density\n",
      "column 2:Delta\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAEHCAYAAAC6DK9EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRX3/wEFO0M55LCiGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22fff218b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please input rho密度最小值22\n",
      "please input delta距离最小值660\n",
      "NUMBER OF CLUSTERS: 3 \n",
      "\n",
      "Performing assignation\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAEHCAYAAAC6DK9EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzEVERDLu/wP3JS0snbCyEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22fff5261d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打点结束\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "完成聚类任务。\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] =(8.0,4.0) # 设置figure_size尺寸\n",
    "plt.rcParams['image.interpolation'] = 'nearest' # 设置 interpolation style\n",
    "plt.rcParams['image.cmap'] = 'gray' # 设置 颜色 style\n",
    "\n",
    "#防止绘图出现乱码的问题\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 步骤一（替换sans-serif字体）\n",
    "plt.rcParams['axes.unicode_minus'] = False   # 步骤二（解决坐标轴负数的负号显示问题）\n",
    "\n",
    "#加载文件\n",
    "print(\"加载文件\")\n",
    "xx=pd.read_csv('each_other_dist.csv',sep=\",\",header=None)\n",
    "\n",
    "NL=max(xx[0])\n",
    "ND=max(xx[1])\n",
    "print(NL)\n",
    "if NL>ND:\n",
    "    ND=NL #确保 ND 取为第一二列最大值中的较大者，并将其作为数据点总数\n",
    "N = len(xx)#距离个数  xx 第一个维度的长度，相当于文件的行数（即距离的总个数）\n",
    "\n",
    "#初始化为dist数组为0\n",
    "print(ND)\n",
    "dist=np.zeros([ND,ND])\n",
    "print(dist.shape[0])\n",
    "#print(xx[2][2000])\n",
    "\n",
    "#为dist数组赋值\n",
    "for i in range(N):\n",
    "    ii = xx[0][i]-1\n",
    "    jj = xx[1][i]-1\n",
    "    #将距离赋予矩阵\n",
    "    dist[ii][jj]=xx[2][i]\n",
    "    dist[jj][ii]=xx[2][i]\n",
    "# 测试赋值所需时间\n",
    "\n",
    "#取截断距离\n",
    "percent=2.0\n",
    "print(\"average percentage of neighbours:\",percent)\n",
    "\n",
    "position=round(N*percent/100); #round 是一个四舍五入函数\n",
    "sda=xx[2].sort_values().tolist()\n",
    "dc=sda[position]\n",
    "#输出截断距离\n",
    "print(\"截断距离是:\",dc)\n",
    "\n",
    "#计算局部密度 rho(用Gaussian高斯核）\n",
    "from math import exp\n",
    "\n",
    "#1.将每个数据点的rho值初始化为0\n",
    "rho=np.zeros(ND)\n",
    "\n",
    " #\"Cut off\" kernel\n",
    "\n",
    "for i in range(1,ND-1):\n",
    "    for j in range(i+1,ND):\n",
    "        if dist[i,j]<dc:\n",
    "            rho[i]=rho[i]+1.;\n",
    "            rho[j]=rho[j]+1.;\n",
    "\n",
    "# 先求矩阵列最大值，再求最大值，最后得到所有距离值中的最大值\n",
    "maxd=dist.max()\n",
    "print(maxd)\n",
    "\n",
    "#将密度rho降序排列，ordho保持序\n",
    "ordrho = np.argsort(-1*rho)\n",
    "rho_sorted =rho[ordrho]\n",
    "\n",
    "#初始化delta数组和nneigh数组\n",
    "delta=[maxd]*ND\n",
    "nneigh=[0]*ND\n",
    " #处理 rho 值最大的数据点\n",
    "delta[ordrho[0]] = -1\n",
    "nneigh[ordrho[0]] = 0\n",
    "\n",
    "#delta 和 nneigh 数组赋值\n",
    "for ii in range(1,ND):\n",
    "    for jj in range(0,ii):\n",
    "        if dist[ordrho[ii],ordrho[jj]]<delta[ordrho[ii]]:\n",
    "            delta[ordrho[ii]]=dist[ordrho[ii],ordrho[jj]]\n",
    "            nneigh[ordrho[ii]]=ordrho[jj]\n",
    "# 记录 rho 值更大的数据点中与 ordrho(ii) 距离最近的点的编号 ordrho(jj)\n",
    "\n",
    "# 生成 rho 值最大数据点的 delta 值\n",
    "delta[ordrho[0]]=max(delta)\n",
    "\n",
    "# 决策图\n",
    "print('Generated file:DECISION GRAPH')\n",
    "print('column 1:Density')\n",
    "print('column 2:Delta')\n",
    "#开画图文件写画图文件\n",
    "with open(cluster_message_path+'DECISION_GRAPH','w') as fid:\n",
    "    for i in range(ND):\n",
    "        fid.write('%6.2f %6.2f\\n'%(rho[i],delta[i]))\n",
    "#选择一个围住类中心的矩形\n",
    "#print('Select a rectangle enclosing cluster centers')\n",
    "#scrsz = get(0,'ScreenSize');\n",
    "#figure('Position',[6 72 scrsz(3)/4. scrsz(4)/1.3]);\n",
    "plt.xlabel('密度rho')\n",
    "plt.ylabel('距离delta')\n",
    "plt.scatter(rho,delta)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#输入选取聚类中心的范围（最小值）\n",
    "rhomin=int(input(\"please input rho密度最小值\"))\n",
    "deltamin=float(input(\"please input delta距离最小值\"))\n",
    "\n",
    "#初始化 cluster 个数\n",
    "NCLUST=0;\n",
    "\n",
    "# cl 为归属标志数组，cl[i]=j 表示第 i 号数据点归属于第 j 个 cluster\n",
    "#先统一将 cl 初始化为 -1\n",
    "cl=[-1]*ND\n",
    "#初始化 点映射到类别列表\n",
    "icl=[-1]*10\n",
    "\n",
    "#在矩形区域内统计数据点（即聚类中心）的个数\n",
    "for i in range(ND):\n",
    "    if  (rho[i]>rhomin) and (delta[i]>deltamin):\n",
    "        NCLUST=NCLUST+1;\n",
    "        cl[i]=NCLUST # 第 i 号数据点属于第 NCLUST 个 cluster\n",
    "        #icl[NCLUST]=i # 逆映射,第 NCLUST 个 cluster 的中心为第 i 号数据点\n",
    "\n",
    "print('NUMBER OF CLUSTERS: %i \\n'%NCLUST)\n",
    "print('Performing assignation')\n",
    "\n",
    "#将其他数据点归类 (assignation)\n",
    "for i in range(ND):\n",
    "    if (cl[ordrho[i]]==-1):\n",
    "        cl[ordrho[i]]=cl[nneigh[ordrho[i]]]\n",
    "\n",
    "#由于是按照 rho 值从大到小的顺序遍历,循环结束后, cl 应该都变成正的值了\n",
    "\n",
    "halo=[-1]*ND\n",
    "rho_aver=0\n",
    "#处理光晕点：\n",
    "if (NCLUST>1):\n",
    "    for i in range(ND):\n",
    "        halo[i]=cl[i]\n",
    "    bord_rho=np.zeros(NCLUST+1)\n",
    "#初始化数组 bord_rho 为 0,每个 cluster 定义一个 bord_rho 值\n",
    "#获取每一个 cluster 中平均密度的一个界 bord_rho\n",
    "    for i in range(ND - 1):\n",
    "        for j in range(i+1,ND):\n",
    "# 距离足够小但不属于同一个cluster的i和j\n",
    "            if (cl[i]!=cl[j]) and (dist[i,j]<= dc):\n",
    "                rho_aver = (rho[i] + rho[j]) / 2\n",
    "# 取i, j两点的平均局部密度\n",
    "                if rho_aver > bord_rho[cl[i]]:\n",
    "                    bord_rho[cl[i]] = rho_aver\n",
    "\n",
    "                if rho_aver > bord_rho[cl[j]]:\n",
    "                    bord_rho[cl[j]] = rho_aver\n",
    "\n",
    "\n",
    "\n",
    "#halo 值为 0 表示为 outlier\n",
    "for i in range(ND):\n",
    "    if rho[i]<bord_rho[cl[i]]:\n",
    "        halo[i]=0\n",
    "\n",
    "#逐一处理每个 cluster\n",
    "for i in range(NCLUST):\n",
    "    nc=0; #用于累计当前 cluster 中数据点的个数\n",
    "    nh=0; # 用于累计当前 cluster 中核心数据点的个数\n",
    "    for j in range(ND):\n",
    "        if cl[j]==i:\n",
    "            nc=nc+1\n",
    "\n",
    "        if halo[j]==i:\n",
    "            nh=nh+1\n",
    "\n",
    "#写聚类后的打标文件\n",
    "with open(cluster_message_path+'clustered_data.txt','w') as fp:\n",
    "    for i in range(ND):\n",
    "        fp.write('%d,%6.2f,%6.2f,%d\\n'%(i,rho[i],delta[i],cl[i]))\n",
    "\n",
    "\n",
    "colors = ['b','g','r','orange','c','m','y','k','w','p','gray','darkred','peru','sandybrown','pink','cyan']\n",
    "plt.xlabel('密度rho')\n",
    "plt.ylabel('距离delta')\n",
    "for i in range(ND):\n",
    "    for j in range(len(colors)):\n",
    "        if int(cl[i]) == j:\n",
    "            plt.scatter(rho[i], delta[i],c=colors[j])\n",
    "            continue\n",
    "plt.show()\n",
    "print(\"打点结束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建BP网络，部分训练集\n",
    "\n",
    "* 多分类网络，经过统计数据分为16类。\n",
    "* 利用文件的data和label构建数据集，先用测试集训练网络。\n",
    "* 构建var数据集，pytorch神经元接受var输入。\n",
    "* 利用pytorch搭建多分类网络（网络分为回归和分类）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_files(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            scio.loadmat(os.path.join(root, name))\n",
    "        print(\"finished\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data finished!\n"
     ]
    }
   ],
   "source": [
    "#训练集和测试集的列表，这里用列表存储np.array\n",
    "train_x,train_y=[],[]\n",
    "\n",
    "for root, dirs, files in os.walk(data_train_path):\n",
    "    for name in files:\n",
    "        src=scio.loadmat(os.path.join(root, name))\n",
    "        src_data=src[\"data\"].reshape(5500)\n",
    "        train_x.append(src_data)\n",
    "        train_y_now=src[\"label\"]-1\n",
    "        train_y.append(train_y_now[0])\n",
    "    print(\"load data finished!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=Variable(torch.FloatTensor(train_x))\n",
    "y=Variable(torch.FloatTensor(train_y)).reshape(1073,).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1073, 5500])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1073, 5500])\n",
      "torch.Size([1073])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络结构\n",
    "\n",
    "* 5500->1800->600->200->16 0.86\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden_1): Linear(in_features=5500, out_features=2000, bias=True)\n",
      "  (hidden_2): Linear(in_features=2000, out_features=500, bias=True)\n",
      "  (hidden_3): Linear(in_features=500, out_features=200, bias=True)\n",
      "  (predict): Linear(in_features=200, out_features=16, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\desk\\Desktop\\Programming_and_Learning\\anconda\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=1.00\n",
      "Accuracy=1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,n_feature,n_hidden_1,n_hidden_2,n_hidden_3,n_output):\n",
    "        super(Net,self).__init__()\n",
    "        self.hidden_1=torch.nn.Linear(n_feature,n_hidden_1)\n",
    "        self.hidden_2=torch.nn.Linear(n_hidden_1,n_hidden_2)\n",
    "        self.hidden_3=torch.nn.Linear(n_hidden_2,n_hidden_3)\n",
    "        self.predict=torch.nn.Linear(n_hidden_3,n_output)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.hidden_1(x))\n",
    "        x=F.relu(self.hidden_2(x))\n",
    "        x=F.relu(self.hidden_3(x))\n",
    "   \n",
    "        x=self.predict(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "net=Net(5500,2000,500,200,16)\n",
    "print(net)\n",
    "\n",
    "#学习率设置一般可以选择设置小一点，因为学习率设置过大，可能会导致它少学习到很多特征。\n",
    "optimizer=torch.optim.SGD(net.parameters(),lr=0.002)\n",
    "\n",
    "#torch.nn.CrossEntropyLoss()计算交叉熵损失\n",
    "loss_func=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "#动态\n",
    "\n",
    "for t in range(1000):\n",
    "    out = net(x) \n",
    "    loss = loss_func(out, y)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    #softmax激活函数，将输出转化为概率。torch.max将最大值的概率输出\n",
    "    _, prediction = torch.max(F.softmax(out), 1)\n",
    "    pred_y = prediction.data.numpy().squeeze()\n",
    "    target_y = y.data.numpy()\n",
    "    accuracy = sum(pred_y == target_y)/1073\n",
    "    if t==499 or t==999:\n",
    "        print(\"Accuracy=%.2f\"% accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用bp网络多多分类任务，精度。。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(net, 'BPggp.pkl')  # save entire net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型之后，利用测试集进行测试\n",
    "* 加载模型\n",
    "* 加载测试集数据\n",
    "* 利用测试集测试精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data finished!\n"
     ]
    }
   ],
   "source": [
    "test_x,test_y=[],[]\n",
    "\n",
    "for root, dirs, files in os.walk(data_test_path):\n",
    "    for name in files:\n",
    "        src=scio.loadmat(os.path.join(root, name))\n",
    "        src_data=src[\"data\"].reshape(5500)\n",
    "        test_x.append(src_data)\n",
    "        test_y_now=src[\"label\"]-1\n",
    "        test_y.append(test_y_now[0])\n",
    "    print(\"load data finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test=Variable(torch.FloatTensor(test_x))\n",
    "y_test=Variable(torch.FloatTensor(test_y)).reshape(335,).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_test=torch.load(\"BPggp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\desk\\Desktop\\Programming_and_Learning\\anconda\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=1.00\n"
     ]
    }
   ],
   "source": [
    "out = net(x_test) \n",
    "#softmax激活函数，将输出转化为概率。torch.max将最大值的概率输出\n",
    "_, prediction = torch.max(F.softmax(out), 1)\n",
    "pred_y = prediction.data.numpy().squeeze()\n",
    "target_y = y_test.data.numpy()\n",
    "accuracy = sum(pred_y == target_y)/335\n",
    "\n",
    "print(\"Accuracy=%.2f\"% accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 重划分一个比较大的测试集\n",
    "## 用模型进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_file=scio.loadmat(label_file_name)\n",
    "data_file=scio.loadmat(data_file_name)\n",
    "\n",
    "\n",
    "label_array=label_file['indian_pines_gt']\n",
    "data_array=data_file['indian_pines']\n",
    "\n",
    "\n",
    "#矩阵类型为numpy.array，shape为145*145*220。\n",
    "#处理矩阵外围数据\n",
    "\n",
    "data_fin_array=np.zeros([151,151,220],np.uint8)\n",
    "data_fin_array[3:148,3:148,:]=data_array\n",
    "\n",
    "index=0\n",
    "\n",
    "#构建总数据集\n",
    "#构建训练集\n",
    "#构建测试集\n",
    "for i in range(3,148):\n",
    "    for j in range(3,148):\n",
    "        index+=1\n",
    "        #不为0符合添加条件\n",
    "        if label_array[i-3][j-3]!=0 :\n",
    "            if index%15==0:\n",
    "                data_now=data_fin_array[i-3:i+4,j-3:j+4,:]\n",
    "                scio.savemat(data_test_new_path+str(i)+str(j)+\".mat\",{\"label\":label_array[i-3][j-3],\"data\":data_now})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data finished!\n"
     ]
    }
   ],
   "source": [
    "test_new_x,test_new_y=[],[]\n",
    "\n",
    "for root, dirs, files in os.walk(data_test_new_path):\n",
    "    for name in files:\n",
    "        src=scio.loadmat(os.path.join(root, name))\n",
    "        src_data=src[\"data\"].reshape(5500)\n",
    "        test_new_x.append(src_data)\n",
    "        test_new_y_now=src[\"label\"]-1\n",
    "        test_new_y.append(test_new_y_now[0])\n",
    "    print(\"load data finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_new_test=Variable(torch.FloatTensor(test_new_x))\n",
    "y_new_test=Variable(torch.FloatTensor(test_new_y)).reshape(665,).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([665, 5500])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\desk\\Desktop\\Programming_and_Learning\\anconda\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.86\n"
     ]
    }
   ],
   "source": [
    "out = net(x_new_test) \n",
    "#softmax激活函数，将输出转化为概率。torch.max将最大值的概率输出\n",
    "_, prediction = torch.max(F.softmax(out), 1)\n",
    "pred_y = prediction.data.numpy().squeeze()\n",
    "target_y = y_new_test.data.numpy()\n",
    "accuracy = sum(pred_y == target_y)/665\n",
    "\n",
    "print(\"Accuracy=%.2f\"% accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3D卷积CNN训练高光谱数据集\n",
    "\n",
    "* 构造数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data finished!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_x,train_y=[],[]\n",
    "\n",
    "for root, dirs, files in os.walk(data_train_path):\n",
    "    for name in files:\n",
    "        src=scio.loadmat(os.path.join(root, name))\n",
    "        src_data=src[\"data\"]\n",
    "        train_x.append(src_data)\n",
    "        train_y_now=src[\"label\"]-1\n",
    "        train_y.append(train_y_now[0])\n",
    "    print(\"load data finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data finished!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_x,test_y=[],[]\n",
    "\n",
    "for root, dirs, files in os.walk(data_test_path):\n",
    "    for name in files:\n",
    "        src=scio.loadmat(os.path.join(root, name))\n",
    "        src_data=src[\"data\"]\n",
    "        test_x.append(src_data)\n",
    "        test_y_now=src[\"label\"]-1\n",
    "        test_y.append(test_y_now[0])\n",
    "    print(\"load data finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test=Variable(torch.FloatTensor(test_x))\n",
    "y_test=Variable(torch.FloatTensor(test_y)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "class_num={}\n",
    "for i in y_train:\n",
    "    if i not in class_num.keys():\n",
    "        class_num[str(i)]=0\n",
    "    else:\n",
    "        class_num[str(i)]+=1\n",
    "    \n",
    "print(len(class_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10) tensor(10) tensor(10) tensor(10) tensor(10) tensor(10) tensor(10) tensor(10) tensor(10) tensor(10) \n",
      "tensor(10) tensor(10) tensor(10) tensor(5) tensor(10) tensor(10) tensor(10) tensor(10) tensor(10) tensor(5) \n",
      "tensor(10) tensor(10) tensor(10) tensor(10) tensor(10) tensor(5) tensor(10) tensor(10) tensor(5) tensor(10) \n",
      "tensor(10) tensor(5) tensor(10) tensor(5) tensor(10) tensor(5) tensor(10) tensor(5) tensor(5) tensor(10) \n",
      "tensor(10) tensor(10) tensor(10) tensor(10) tensor(5) tensor(10) tensor(5) tensor(5) tensor(10) tensor(5) \n",
      "tensor(10) tensor(10) tensor(5) tensor(5) tensor(10) tensor(10) tensor(5) tensor(5) tensor(10) tensor(10) \n",
      "tensor(10) tensor(10) tensor(10) tensor(10) tensor(5) tensor(5) tensor(5) tensor(5) tensor(5) tensor(10) \n",
      "tensor(10) tensor(10) tensor(10) tensor(5) tensor(5) tensor(5) tensor(5) tensor(14) tensor(5) tensor(14) \n",
      "tensor(10) tensor(10) tensor(5) tensor(5) tensor(10) tensor(10) tensor(5) tensor(5) tensor(5) tensor(10) \n",
      "tensor(10) tensor(5) tensor(10) tensor(10) tensor(5) tensor(10) tensor(10) tensor(14) tensor(10) tensor(2) \n",
      "tensor(10) tensor(5) tensor(10) tensor(5) tensor(10) tensor(5) tensor(10) tensor(5) tensor(5) tensor(10) \n",
      "tensor(10) tensor(5) tensor(5) tensor(10) tensor(2) tensor(10) tensor(5) tensor(10) tensor(10) tensor(5) \n",
      "tensor(10) tensor(10) tensor(5) tensor(5) tensor(5) tensor(10) tensor(10) tensor(10) tensor(10) tensor(10) \n",
      "tensor(10) tensor(10) tensor(10) tensor(10) tensor(5) tensor(5) tensor(5) tensor(5) tensor(5) tensor(14) \n",
      "tensor(10) tensor(10) tensor(5) tensor(5) tensor(5) tensor(5) tensor(10) tensor(5) tensor(10) tensor(10) \n",
      "tensor(10) tensor(5) tensor(5) tensor(10) tensor(10) tensor(10) tensor(10) tensor(5) tensor(13) tensor(13) \n",
      "tensor(10) tensor(5) tensor(10) tensor(5) tensor(5) tensor(5) tensor(10) tensor(10) tensor(13) tensor(13) \n",
      "tensor(10) tensor(5) tensor(10) tensor(5) tensor(10) tensor(5) tensor(10) tensor(13) tensor(13) tensor(12) \n",
      "tensor(10) tensor(10) tensor(5) tensor(10) tensor(10) tensor(10) tensor(10) tensor(10) tensor(13) tensor(12) \n",
      "tensor(10) tensor(10) tensor(5) tensor(14) tensor(10) tensor(10) tensor(5) tensor(12) tensor(13) tensor(12) \n",
      "tensor(10) tensor(10) tensor(10) tensor(10) tensor(5) tensor(10) tensor(13) tensor(12) tensor(13) tensor(4) \n",
      "tensor(10) tensor(5) tensor(5) tensor(14) tensor(10) tensor(5) tensor(10) tensor(12) tensor(13) tensor(13) \n",
      "tensor(10) tensor(5) tensor(2) tensor(5) tensor(10) tensor(14) tensor(12) tensor(12) tensor(13) tensor(13) \n",
      "tensor(10) tensor(5) tensor(10) tensor(10) tensor(5) tensor(5) tensor(12) tensor(13) tensor(13) tensor(10) \n",
      "tensor(10) tensor(5) tensor(5) tensor(10) tensor(10) tensor(13) tensor(13) tensor(13) tensor(13) tensor(13) \n",
      "tensor(10) tensor(10) tensor(5) tensor(10) tensor(10) tensor(13) tensor(13) tensor(13) tensor(13) tensor(13) \n",
      "tensor(10) tensor(10) tensor(5) tensor(5) tensor(5) tensor(10) tensor(4) tensor(13) tensor(13) tensor(13) \n",
      "tensor(10) tensor(10) tensor(10) tensor(2) tensor(10) tensor(13) tensor(12) tensor(13) tensor(13) tensor(13) \n",
      "tensor(10) tensor(5) tensor(5) tensor(10) tensor(10) tensor(12) tensor(13) tensor(4) tensor(13) tensor(2) \n",
      "tensor(10) tensor(11) tensor(5) tensor(9) tensor(14) tensor(13) tensor(13) tensor(2) tensor(13) tensor(2) \n",
      "tensor(10) tensor(5) tensor(10) tensor(10) tensor(13) tensor(13) tensor(4) tensor(10) tensor(13) tensor(13) \n",
      "tensor(10) tensor(5) tensor(5) tensor(5) tensor(4) tensor(12) tensor(4) tensor(13) tensor(2) tensor(13) \n",
      "tensor(10) tensor(10) tensor(5) tensor(10) tensor(13) tensor(13) tensor(13) tensor(13) tensor(13) tensor(2) \n",
      "tensor(10) tensor(10) tensor(5) tensor(5) tensor(12) tensor(13) tensor(13) tensor(2) tensor(13) tensor(9) \n",
      "tensor(10) tensor(10) tensor(10) tensor(10) tensor(13) tensor(12) tensor(2) tensor(2) tensor(14) tensor(11) \n",
      "tensor(10) tensor(5) tensor(5) tensor(5) tensor(12) tensor(13) tensor(10) tensor(11) tensor(10) tensor(10) \n",
      "tensor(10) tensor(5) tensor(10) tensor(10) tensor(13) tensor(4) tensor(13) tensor(2) tensor(2) tensor(10) \n",
      "tensor(10) tensor(5) tensor(2) tensor(10) tensor(4) tensor(13) tensor(2) tensor(13) tensor(11) tensor(15) \n",
      "tensor(10) tensor(5) tensor(10) tensor(5) tensor(13) tensor(13) tensor(9) tensor(14) tensor(9) tensor(10) \n",
      "tensor(10) tensor(10) tensor(5) tensor(14) tensor(4) tensor(2) tensor(13) tensor(13) tensor(11) tensor(10) \n",
      "tensor(10) tensor(10) tensor(5) tensor(13) tensor(13) tensor(13) tensor(13) tensor(10) tensor(11) tensor(14) \n",
      "tensor(10) tensor(10) tensor(10) tensor(12) tensor(4) tensor(13) tensor(2) tensor(9) tensor(10) tensor(1) \n",
      "tensor(10) tensor(5) tensor(10) tensor(10) tensor(13) tensor(10) tensor(2) tensor(9) tensor(10) tensor(15) \n",
      "tensor(10) tensor(5) tensor(5) tensor(13) tensor(4) tensor(13) tensor(13) tensor(10) tensor(13) tensor(1) \n",
      "tensor(10) tensor(2) tensor(10) tensor(12) tensor(13) tensor(2) tensor(13) tensor(10) tensor(13) tensor(2) \n",
      "tensor(10) tensor(10) tensor(10) tensor(13) tensor(4) tensor(13) tensor(13) tensor(10) tensor(14) tensor(10) \n",
      "tensor(10) tensor(10) tensor(5) tensor(12) tensor(13) tensor(2) tensor(9) tensor(11) tensor(11) tensor(10) \n",
      "tensor(10) tensor(10) tensor(11) tensor(4) tensor(13) tensor(13) tensor(13) tensor(10) tensor(11) tensor(2) \n",
      "tensor(10) tensor(5) tensor(10) tensor(13) tensor(13) tensor(13) tensor(2) tensor(10) tensor(11) tensor(2) \n",
      "tensor(10) tensor(14) tensor(5) tensor(12) tensor(4) tensor(11) tensor(9) tensor(1) tensor(14) tensor(2) \n",
      "tensor(10) tensor(5) tensor(10) tensor(13) tensor(13) tensor(13) tensor(10) tensor(11) tensor(10) tensor(1) \n",
      "tensor(10) tensor(5) tensor(10) tensor(12) tensor(2) tensor(13) tensor(11) tensor(1) tensor(10) tensor(2) \n",
      "tensor(10) tensor(5) tensor(5) tensor(4) tensor(13) tensor(2) tensor(11) tensor(11) tensor(10) tensor(1) \n",
      "tensor(10) tensor(10) tensor(10) tensor(13) tensor(2) tensor(13) tensor(2) tensor(1) tensor(2) tensor(3) \n",
      "tensor(10) tensor(10) tensor(10) tensor(12) tensor(13) tensor(13) tensor(10) tensor(15) tensor(2) tensor(14) \n",
      "tensor(10) tensor(10) tensor(14) tensor(13) tensor(2) tensor(13) tensor(13) tensor(15) tensor(13) tensor(13) \n",
      "tensor(10) tensor(5) tensor(10) tensor(13) tensor(13) tensor(10) tensor(10) tensor(14) tensor(13) tensor(14) \n",
      "tensor(10) tensor(14) tensor(5) tensor(12) tensor(9) tensor(13) tensor(10) tensor(10) tensor(13) tensor(14) \n",
      "tensor(10) tensor(5) tensor(14) tensor(13) tensor(13) tensor(9) tensor(15) tensor(10) tensor(2) tensor(2) \n",
      "tensor(10) tensor(10) tensor(4) tensor(12) tensor(11) tensor(9) tensor(15) tensor(10) tensor(9) tensor(14) \n",
      "tensor(10) tensor(10) tensor(13) tensor(4) tensor(13) tensor(10) tensor(14) tensor(2) tensor(2) tensor(1) \n",
      "tensor(10) tensor(10) tensor(12) tensor(13) tensor(13) tensor(11) tensor(15) tensor(2) tensor(14) tensor(7) \n",
      "tensor(10) tensor(5) tensor(4) tensor(4) tensor(2) tensor(13) tensor(14) tensor(2) tensor(13) tensor(9) \n",
      "tensor(10) tensor(14) tensor(10) tensor(13) tensor(2) tensor(10) tensor(15) tensor(2) tensor(14) tensor(9) \n",
      "tensor(10) tensor(5) tensor(13) tensor(13) tensor(13) tensor(11) tensor(11) tensor(13) tensor(2) tensor(1) \n",
      "tensor(10) tensor(5) tensor(10) tensor(2) tensor(2) tensor(13) tensor(1) tensor(2) tensor(7) tensor(1) \n",
      "tensor(10) tensor(5) tensor(12) tensor(13) tensor(13) tensor(13) tensor(2) tensor(1) tensor(1) tensor(7) \n",
      "tensor(10) tensor(10) tensor(4) tensor(13) tensor(13) tensor(11) tensor(10) tensor(1) tensor(7) tensor(7) \n",
      "tensor(10) tensor(10) tensor(13) tensor(2) tensor(14) tensor(11) tensor(10) tensor(13) tensor(10) tensor(2) \n",
      "tensor(10) tensor(10) tensor(12) tensor(10) tensor(9) tensor(1) tensor(10) tensor(1) tensor(1) tensor(1) \n",
      "tensor(10) tensor(5) tensor(12) tensor(10) tensor(10) tensor(11) tensor(2) tensor(14) tensor(7) tensor(7) \n",
      "tensor(10) tensor(5) tensor(13) tensor(2) tensor(10) tensor(11) tensor(2) tensor(7) tensor(2) tensor(3) \n",
      "tensor(10) tensor(10) tensor(13) tensor(13) tensor(2) tensor(14) tensor(2) tensor(14) tensor(1) tensor(9) \n",
      "tensor(10) tensor(10) tensor(12) tensor(2) tensor(9) tensor(1) tensor(13) tensor(14) tensor(1) tensor(9) \n",
      "tensor(10) tensor(2) tensor(4) tensor(2) tensor(11) tensor(13) tensor(1) tensor(13) tensor(3) tensor(3) \n",
      "tensor(10) tensor(10) tensor(13) tensor(13) tensor(10) tensor(11) tensor(1) tensor(14) tensor(9) tensor(7) \n",
      "tensor(10) tensor(10) tensor(13) tensor(9) tensor(9) tensor(11) tensor(13) tensor(9) tensor(1) tensor(7) \n",
      "tensor(10) tensor(10) tensor(12) tensor(2) tensor(10) tensor(15) tensor(1) tensor(1) tensor(7) tensor(10) \n",
      "tensor(10) tensor(5) tensor(4) tensor(13) tensor(11) tensor(1) tensor(1) tensor(13) tensor(1) tensor(1) \n",
      "tensor(10) tensor(5) tensor(13) tensor(2) tensor(10) tensor(11) tensor(2) tensor(1) tensor(1) tensor(9) \n",
      "tensor(10) tensor(5) tensor(13) tensor(13) tensor(11) tensor(10) tensor(2) tensor(7) tensor(7) tensor(11) \n",
      "tensor(10) tensor(2) tensor(12) tensor(13) tensor(10) tensor(10) tensor(14) tensor(9) tensor(9) tensor(5) \n",
      "tensor(10) tensor(10) tensor(4) tensor(2) tensor(10) tensor(10) tensor(2) tensor(1) tensor(1) tensor(11) \n",
      "tensor(10) tensor(10) tensor(13) tensor(13) tensor(11) tensor(10) tensor(7) tensor(7) tensor(7) tensor(11) \n",
      "tensor(10) tensor(10) tensor(13) tensor(2) tensor(10) tensor(2) tensor(14) tensor(9) tensor(1) tensor(9) \n",
      "tensor(10) tensor(5) tensor(12) tensor(13) tensor(11) tensor(2) tensor(9) tensor(1) tensor(9) tensor(11) \n",
      "tensor(10) tensor(5) tensor(4) tensor(13) tensor(13) tensor(13) tensor(13) tensor(10) tensor(10) tensor(5) \n",
      "tensor(10) tensor(9) tensor(13) tensor(2) tensor(15) tensor(9) tensor(2) tensor(1) tensor(11) tensor(7) \n",
      "tensor(10) tensor(10) tensor(13) tensor(13) tensor(13) tensor(13) tensor(1) tensor(7) tensor(11) tensor(1) \n",
      "tensor(10) tensor(10) tensor(12) tensor(13) tensor(11) tensor(1) tensor(13) tensor(14) tensor(9) tensor(9) \n",
      "tensor(10) tensor(10) tensor(4) tensor(13) tensor(14) tensor(1) tensor(1) tensor(7) tensor(11) tensor(9) \n",
      "tensor(10) tensor(5) tensor(13) tensor(13) tensor(11) tensor(2) tensor(13) tensor(1) tensor(11) tensor(9) \n",
      "tensor(10) tensor(5) tensor(13) tensor(9) tensor(11) tensor(1) tensor(1) tensor(1) tensor(7) tensor(9) \n",
      "tensor(10) tensor(5) tensor(4) tensor(13) tensor(14) tensor(13) tensor(9) tensor(7) tensor(9) tensor(10) \n",
      "tensor(10) tensor(11) tensor(13) tensor(13) tensor(11) tensor(1) tensor(1) tensor(9) tensor(5) tensor(9) \n",
      "tensor(10) tensor(10) tensor(13) tensor(13) tensor(11) tensor(13) tensor(3) tensor(2) tensor(7) tensor(9) \n",
      "tensor(10) tensor(10) tensor(13) tensor(2) tensor(11) tensor(2) tensor(1) tensor(1) tensor(10) tensor(9) \n",
      "tensor(10) tensor(10) tensor(2) tensor(9) tensor(11) tensor(1) tensor(7) tensor(9) tensor(10) tensor(10) \n",
      "tensor(10) tensor(5) tensor(4) tensor(9) tensor(14) tensor(14) tensor(9) tensor(11) tensor(2) tensor(10) \n",
      "tensor(10) tensor(5) tensor(13) tensor(9) tensor(2) tensor(13) tensor(7) tensor(10) tensor(1) tensor(1) \n",
      "tensor(10) tensor(10) tensor(13) tensor(10) tensor(10) tensor(14) tensor(9) tensor(9) tensor(9) tensor(6) \n",
      "tensor(10) tensor(10) tensor(2) tensor(2) tensor(10) tensor(1) tensor(1) tensor(11) tensor(10) tensor(1) \n",
      "tensor(10) tensor(10) tensor(2) tensor(11) tensor(10) tensor(9) tensor(2) tensor(10) tensor(10) tensor(1) \n",
      "tensor(10) tensor(5) tensor(13) tensor(10) tensor(10) tensor(13) tensor(3) tensor(9) tensor(1) tensor(1) \n",
      "tensor(10) tensor(5) tensor(13) tensor(11) tensor(10) tensor(7) tensor(1) tensor(11) tensor(5) tensor(1) \n",
      "tensor(10) tensor(5) tensor(10) tensor(10) tensor(2) tensor(14) tensor(7) tensor(10) tensor(2) tensor(10) \n",
      "tensor(10) tensor(10) tensor(2) tensor(2) tensor(2) tensor(1) tensor(9) tensor(11) tensor(2) tensor(10) \n"
     ]
    }
   ],
   "source": [
    "for i in range(107):\n",
    "    for j in range(10):\n",
    "        print(y_train[i*j],end=\" \")\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test=y_test.reshape(336,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10,  5, 10,  5, 10,  5, 10,  5, 10,  5,  5, 10,  5,  2, 10,  5, 10,\n",
       "         5, 10, 14,  5, 10, 10,  2, 10,  5,  5, 10,  5, 10,  5, 11, 10,  5, 10,\n",
       "        10, 14, 10,  5, 13, 12, 10, 13,  4, 13, 12,  4, 13, 12, 13, 13, 12, 11,\n",
       "        13, 13, 12, 13, 12, 13, 12,  4, 14, 13,  4, 13, 13,  2, 13, 13,  2, 13,\n",
       "        13, 10,  2, 13,  2,  2, 13,  2, 13,  2, 13, 13, 11,  2, 13,  2, 13, 13,\n",
       "         2, 13, 14, 13, 13, 13, 13, 10,  9, 13,  9,  9,  9, 14,  9, 11, 14, 13,\n",
       "        11, 14, 10, 13, 11, 10, 10,  2, 15, 10, 11, 14, 11, 13, 11,  1, 13, 11,\n",
       "        11,  1, 15,  1, 15, 11, 14, 11, 11,  1, 13, 13,  1,  1,  1, 13,  1, 13,\n",
       "         2,  1,  9, 13,  2,  1, 13,  1,  9, 13, 14,  1,  1,  9,  7,  1,  3, 13,\n",
       "         3,  7,  1,  7,  3,  1,  9,  9,  7,  1,  9, 10,  1,  9,  1,  9,  7,  1,\n",
       "         1,  2,  1,  3,  7,  1,  1,  1,  7,  3,  9,  9,  7,  3, 14,  9, 10,  1,\n",
       "         9, 10,  2,  5,  1,  9,  7,  5,  1,  1,  7, 10,  1,  1,  7, 11, 10,  9,\n",
       "         9,  7, 11,  9, 10,  9,  5,  9,  7,  5, 11,  1, 11,  7, 10,  1,  7, 11,\n",
       "        10,  9, 10,  9,  7, 10,  2,  9, 10, 10,  9,  5, 10,  9,  5, 10,  2,  1,\n",
       "         2, 10,  1,  2,  1,  2, 10, 14,  9, 10,  9,  5, 10,  9,  5, 10,  2,  0,\n",
       "         2,  1, 10,  2,  2,  1, 10,  2, 10,  4, 10, 10, 10,  4,  4, 10, 10,  4,\n",
       "        14, 10,  1,  6,  4,  1,  4,  1, 10, 10,  1, 10, 10,  4,  4, 10, 10,  4,\n",
       "        10,  1,  4, 10,  1, 10, 10, 10, 10,  4,  4, 10, 10,  4, 10,  1, 10,  1,\n",
       "        10,  9, 10, 10, 10, 10, 10, 10, 10, 10, 14, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test=x_test.reshape(336,55,-1,7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([336, 55, 4, 7, 7])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取训练集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7, 220)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=Variable(torch.FloatTensor(train_x))\n",
    "y_train=Variable(torch.FloatTensor(train_y)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=y_train.reshape(1078,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10, 10,  ..., 10, 10,  5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1078, 7, 7, 220])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1078])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1078,7,7,220是目前得到的训练集\n",
    "\n",
    "* 需要用到conv3D的话就要对序列信息进行提取。\n",
    "* 因此需要增加维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(1078,55,-1,7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1078, 55, 4, 7, 7])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3D, self).__init__()       \n",
    "        #input:55 7 7\n",
    "        self.conv1 = nn.Sequential( \n",
    "            nn.Conv3d(55,32,kernel_size=(1,3,3),stride=1,padding=(0,1,1)),#[1078, 32, 4, 7, 7]    \n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(),           \n",
    "            nn.MaxPool3d(2)#[1078, 32, 2, 3, 3]   \n",
    "        )  \n",
    "        \n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv3d(32,64,kernel_size=(1,3,3),stride=1,padding=(0,1,1)),\n",
    "            nn.ReLU(),                    \n",
    "            nn.MaxPool3d(2),                \n",
    "        )\n",
    "        self.out = nn.Linear(64 , 16)   # fully connected layer, output 16 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn=CNN3D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN3D(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv3d(55, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=16, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.0002)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | test loss: 2.8736 | test accuracy: 0.04\n",
      "Epoch:  10 | test loss: 2.4094 | test accuracy: 0.24\n",
      "Epoch:  20 | test loss: 2.2279 | test accuracy: 0.32\n",
      "Epoch:  30 | test loss: 2.0858 | test accuracy: 0.36\n",
      "Epoch:  40 | test loss: 1.9534 | test accuracy: 0.36\n",
      "Epoch:  50 | test loss: 1.8321 | test accuracy: 0.38\n",
      "Epoch:  60 | test loss: 1.7192 | test accuracy: 0.40\n",
      "Epoch:  70 | test loss: 1.6132 | test accuracy: 0.43\n",
      "Epoch:  80 | test loss: 1.5141 | test accuracy: 0.47\n",
      "Epoch:  90 | test loss: 1.4211 | test accuracy: 0.51\n",
      "Epoch:  100 | test loss: 1.3337 | test accuracy: 0.54\n",
      "Epoch:  110 | test loss: 1.2517 | test accuracy: 0.59\n",
      "Epoch:  120 | test loss: 1.1752 | test accuracy: 0.62\n",
      "Epoch:  130 | test loss: 1.1041 | test accuracy: 0.65\n",
      "Epoch:  140 | test loss: 1.0372 | test accuracy: 0.71\n",
      "Epoch:  150 | test loss: 0.9731 | test accuracy: 0.74\n",
      "Epoch:  160 | test loss: 0.9114 | test accuracy: 0.75\n",
      "Epoch:  170 | test loss: 0.8512 | test accuracy: 0.79\n",
      "Epoch:  180 | test loss: 0.7923 | test accuracy: 0.82\n",
      "Epoch:  190 | test loss: 0.7347 | test accuracy: 0.86\n",
      "Epoch:  200 | test loss: 0.6787 | test accuracy: 0.88\n",
      "Epoch:  210 | test loss: 0.6244 | test accuracy: 0.90\n",
      "Epoch:  220 | test loss: 0.5719 | test accuracy: 0.91\n",
      "Epoch:  230 | test loss: 0.5220 | test accuracy: 0.93\n",
      "Epoch:  240 | test loss: 0.4746 | test accuracy: 0.95\n",
      "Epoch:  250 | test loss: 0.4301 | test accuracy: 0.96\n",
      "Epoch:  260 | test loss: 0.3887 | test accuracy: 0.97\n",
      "Epoch:  270 | test loss: 0.3506 | test accuracy: 0.98\n",
      "Epoch:  280 | test loss: 0.3158 | test accuracy: 0.98\n",
      "Epoch:  290 | test loss: 0.2843 | test accuracy: 0.99\n",
      "Epoch:  300 | test loss: 0.2559 | test accuracy: 0.99\n",
      "Epoch:  310 | test loss: 0.2304 | test accuracy: 0.99\n",
      "Epoch:  320 | test loss: 0.2076 | test accuracy: 0.99\n",
      "Epoch:  330 | test loss: 0.1874 | test accuracy: 0.99\n",
      "Epoch:  340 | test loss: 0.1692 | test accuracy: 0.99\n",
      "Epoch:  350 | test loss: 0.1532 | test accuracy: 0.99\n",
      "Epoch:  360 | test loss: 0.1391 | test accuracy: 1.00\n",
      "Epoch:  370 | test loss: 0.1265 | test accuracy: 1.00\n",
      "Epoch:  380 | test loss: 0.1153 | test accuracy: 1.00\n",
      "Epoch:  390 | test loss: 0.1053 | test accuracy: 1.00\n",
      "Epoch:  400 | test loss: 0.0965 | test accuracy: 1.00\n",
      "Epoch:  410 | test loss: 0.0885 | test accuracy: 1.00\n",
      "Epoch:  420 | test loss: 0.0814 | test accuracy: 1.00\n",
      "Epoch:  430 | test loss: 0.0751 | test accuracy: 1.00\n",
      "Epoch:  440 | test loss: 0.0694 | test accuracy: 1.00\n",
      "Epoch:  450 | test loss: 0.0643 | test accuracy: 1.00\n",
      "Epoch:  460 | test loss: 0.0597 | test accuracy: 1.00\n",
      "Epoch:  470 | test loss: 0.0556 | test accuracy: 1.00\n",
      "Epoch:  480 | test loss: 0.0519 | test accuracy: 1.00\n",
      "Epoch:  490 | test loss: 0.0486 | test accuracy: 1.00\n",
      "Epoch:  500 | test loss: 0.0455 | test accuracy: 1.00\n",
      "Epoch:  510 | test loss: 0.0427 | test accuracy: 1.00\n",
      "Epoch:  520 | test loss: 0.0402 | test accuracy: 1.00\n",
      "Epoch:  530 | test loss: 0.0379 | test accuracy: 1.00\n",
      "Epoch:  540 | test loss: 0.0357 | test accuracy: 1.00\n",
      "Epoch:  550 | test loss: 0.0338 | test accuracy: 1.00\n",
      "Epoch:  560 | test loss: 0.0319 | test accuracy: 1.00\n",
      "Epoch:  570 | test loss: 0.0303 | test accuracy: 1.00\n",
      "Epoch:  580 | test loss: 0.0287 | test accuracy: 1.00\n",
      "Epoch:  590 | test loss: 0.0273 | test accuracy: 1.00\n",
      "Epoch:  600 | test loss: 0.0260 | test accuracy: 1.00\n",
      "Epoch:  610 | test loss: 0.0248 | test accuracy: 1.00\n",
      "Epoch:  620 | test loss: 0.0236 | test accuracy: 1.00\n",
      "Epoch:  630 | test loss: 0.0225 | test accuracy: 1.00\n",
      "Epoch:  640 | test loss: 0.0215 | test accuracy: 1.00\n",
      "Epoch:  650 | test loss: 0.0206 | test accuracy: 1.00\n",
      "Epoch:  660 | test loss: 0.0197 | test accuracy: 1.00\n",
      "Epoch:  670 | test loss: 0.0189 | test accuracy: 1.00\n",
      "Epoch:  680 | test loss: 0.0182 | test accuracy: 1.00\n",
      "Epoch:  690 | test loss: 0.0174 | test accuracy: 1.00\n",
      "Epoch:  700 | test loss: 0.0168 | test accuracy: 1.00\n",
      "Epoch:  710 | test loss: 0.0161 | test accuracy: 1.00\n",
      "Epoch:  720 | test loss: 0.0155 | test accuracy: 1.00\n",
      "Epoch:  730 | test loss: 0.0150 | test accuracy: 1.00\n",
      "Epoch:  740 | test loss: 0.0144 | test accuracy: 1.00\n",
      "Epoch:  750 | test loss: 0.0139 | test accuracy: 1.00\n",
      "Epoch:  760 | test loss: 0.0134 | test accuracy: 1.00\n",
      "Epoch:  770 | test loss: 0.0130 | test accuracy: 1.00\n",
      "Epoch:  780 | test loss: 0.0126 | test accuracy: 1.00\n",
      "Epoch:  790 | test loss: 0.0121 | test accuracy: 1.00\n",
      "Epoch:  800 | test loss: 0.0118 | test accuracy: 1.00\n",
      "Epoch:  810 | test loss: 0.0114 | test accuracy: 1.00\n",
      "Epoch:  820 | test loss: 0.0110 | test accuracy: 1.00\n",
      "Epoch:  830 | test loss: 0.0107 | test accuracy: 1.00\n",
      "Epoch:  840 | test loss: 0.0104 | test accuracy: 1.00\n",
      "Epoch:  850 | test loss: 0.0101 | test accuracy: 1.00\n",
      "Epoch:  860 | test loss: 0.0098 | test accuracy: 1.00\n",
      "Epoch:  870 | test loss: 0.0095 | test accuracy: 1.00\n",
      "Epoch:  880 | test loss: 0.0092 | test accuracy: 1.00\n",
      "Epoch:  890 | test loss: 0.0089 | test accuracy: 1.00\n",
      "Epoch:  900 | test loss: 0.0087 | test accuracy: 1.00\n",
      "Epoch:  910 | test loss: 0.0085 | test accuracy: 1.00\n",
      "Epoch:  920 | test loss: 0.0082 | test accuracy: 1.00\n",
      "Epoch:  930 | test loss: 0.0080 | test accuracy: 1.00\n",
      "Epoch:  940 | test loss: 0.0078 | test accuracy: 1.00\n",
      "Epoch:  950 | test loss: 0.0076 | test accuracy: 1.00\n",
      "Epoch:  960 | test loss: 0.0074 | test accuracy: 1.00\n",
      "Epoch:  970 | test loss: 0.0072 | test accuracy: 1.00\n",
      "Epoch:  980 | test loss: 0.0070 | test accuracy: 1.00\n",
      "Epoch:  990 | test loss: 0.0069 | test accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    x=x_train\n",
    "    y=y_train\n",
    "    \n",
    "    output=cnn(x)[0]\n",
    "    loss = loss_func(output, y)\n",
    "    optimizer.zero_grad()           # clear gradients for this training step\n",
    "    loss.backward()                 # backpropagation, compute gradients\n",
    "    optimizer.step()   \n",
    "    if epoch % 10 == 0:\n",
    "        test_output, last_layer = cnn(x_test)\n",
    "        pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "        accuracy = (pred_y == y_test).sum().item() / float(y_test.size(0))\n",
    "        print('Epoch: ', epoch, '| test loss: %.4f' % loss.item(), '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型\n",
    "* torch.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of CNN3D(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv3d(55, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (out): Linear(in_features=64, out_features=16, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn,\"Cnn3D.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载网络，利用重构数据集进行测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_1=torch.load(\"Cnn3D.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of CNN3D(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv3d(55, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (out): Linear(in_features=64, out_features=16, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_1.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重构数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data finished!\n"
     ]
    }
   ],
   "source": [
    "test_new_x,test_new_y=[],[]\n",
    "\n",
    "for root, dirs, files in os.walk(data_test_new_path):\n",
    "    for name in files:\n",
    "        src=scio.loadmat(os.path.join(root, name))\n",
    "        src_data=src[\"data\"]\n",
    "        test_new_x.append(src_data)\n",
    "        test_new_y_now=src[\"label\"]-1\n",
    "        test_new_y.append(test_new_y_now[0])\n",
    "    print(\"load data finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_test=Variable(torch.FloatTensor(test_new_x))\n",
    "y_new_test=Variable(torch.FloatTensor(test_new_y)).reshape(664,).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([664, 7, 7, 220])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_new_test.reshape(664,55,-1,7,7)\n",
    "y_test=y_new_test.reshape(664,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| test loss: 0.0067 | test accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "test_output, last_layer = cnn(x_test)\n",
    "pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "accuracy = (pred_y == y_test).sum().item() / float(y_test.size(0))\n",
    "print('| test loss: %.4f' % loss.item(), '| test accuracy: %.2f' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
